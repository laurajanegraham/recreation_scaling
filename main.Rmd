---
title: "Scale-dependency in drivers of outdoor recreation"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

# load_packages
library(gamlss)
library(raster)
library(sf)
library(GGally)
library(broom)
library(MuMIn)
library(knitr)
library(hier.part)
library(patchwork)
library(corrr)
library(jtools)
library(pscl)
library(tidyverse)

# get the functions I've written for variance partitioning negative binomial models
source("code/hier.part.nb.R")

# set up plotting options
theme_set(theme_bw(base_size = 10) + 
            theme(strip.background = element_blank(),
                  panel.grid.major = element_blank(),
                  panel.grid.minor = element_blank()))

# covariates
cov_supply <- c("lcm_agri", 
                "lcm_forest",
                "lcm_coast",
                "lcm_shei", 
                "dem_range", 
                "pa")

cov_supply_lab <- c("Agriculture %", 
                    "Forest %",
                    "Coastal %",
                    "LC Diversity", 
                    "Elevation Range", 
                    "Protected Area")

cov_demand <- c("pop", 
                "dist")

cov_demand_lab <- c("Population density", 
                    "Distance to city")

# study extent
prj <- "+proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +towgs84=446.448,-125.157,542.06,0.15,0.247,0.842,-20.489 +units=m +no_defs"

study_ext_sf <- st_read("~/DATA/ADMINISTRATIVE/gb_shapefile/GBR_adm1.shp", quiet = TRUE) %>% 
  filter(NAME_1 == "England") %>% 
  st_transform(prj)
```

# Data

Response data are MENE visits, and flickr visits. 

For each response type and resolution, the covariates are:

- Proportion of agricultural land cover (lcm_agri; supply)
- Proporiton of natural land covers (lcm_prop; supply)
- Diversity of land-cover types (lcm_shei; supply)
- Amount of protected area (pa; supply)
- Mean elevation (dem_mean; supply)
- Total population (pop; demand)
- Distance to nearest major town or city (dist; demand)

```{r load_data}
load("data/rec_analysis_data.Rda") 

df <- df %>% select(-lcm_prop)
```

## Data exploration 

### Distribution, sample size and coverage of recreation proxies

```{r rec_distribution, fig.height = 4, fig.width = 8}
df_response <- df %>% select(x, y, resolution, mene, flickr) %>% 
  gather(dataset, response, -x, -y, -resolution)

ggplot(df_response, 
       aes(x = response)) + 
  geom_density(alpha = 0.3) + 
  facet_wrap(~ dataset + resolution, scales = "free", nrow = 2)
```

### Distribution of covariates

We are removing the extreme outliers from the data (99.9 percentile) because they are completely driving analysis. Need to write justification for this into the methods. 

```{r outliers}
df %>% group_by(resolution) %>% 
  mutate(qtl = quantile(flickr, 0.99)) %>% 
  filter(flickr > qtl) %>% 
  group_by(resolution) %>% 
  summarise(outliers = n())

df <- df %>% group_by(resolution) %>% 
  mutate(qtl = quantile(flickr, 0.99)) %>% 
  filter(flickr <= qtl) %>% 
  select(-qtl)

```

```{r cov_dist, fig.height = 10, fig.width = 8}
df_narrow <- df %>% 
  select(resolution, cov_supply, cov_demand) %>% 
  gather(variable, value, -resolution)

ggplot(df_narrow, aes(x = value)) + 
      geom_histogram() + 
      facet_wrap(~ variable + resolution, nrow = length(c(cov_supply, cov_demand)), 
                 scales = "free")
```

- lcm_agri: left skew at all resolutions
- lcm_shei: fine
- all others: right skew at all resolutions

We log transform lcm_prop, dem_range, pa, dist and pop; we square transform lcm_agri.

```{r transform}
df_scaled <- df %>% group_by(resolution) %>% 
  nest() %>% 
  mutate(data = map(data, mutate_at, vars(lcm_coast, lcm_forest, dem_range, pa, pop, dist), 
                    function(x) log(x + 1)),
         data = map(data, mutate, lcm_agri = lcm_agri^2),
         data_scale = map(data, mutate_at, vars(cov_supply, cov_demand), 
                          function(x) scale(x) %>% as.vector)) 

df_analysis <- df_scaled %>% 
  select(resolution, data_scale) %>% 
  unnest()

# get mean and sd values from the log-transformed data (for back scaling)
means <- df_scaled %>% 
  select(resolution, data) %>% 
  unnest() %>% 
  group_by(resolution) %>% 
  summarise_all(funs(mean, sd)) %>% 
  gather(key, value, -resolution) 
```

### Correlation between variables

```{r cov_corrs, fig.width = 8}
corrs <- df_analysis %>% 
  select(-x, -y) %>% 
  group_by(resolution) %>% 
  nest() %>% 
  mutate(
    corrs = map(data, function(x) {
      x %>% correlate(quiet = TRUE) %>% shave
    })
  )

map(corrs$corrs, rplot, shape = 15, print_cor = TRUE)
```

High correlation between variables along with small sample size might mean dropping the 50km resolution analysis (for now care to be taken with this analysis). 

# Q1: How similar are proxies for recreation at different scales?

First, check the spatial distribution of the data: 

```{r, fig.width=10, fig.height = 4}
p1 <- ggplot() + 
  geom_sf(data = study_ext_sf, fill = "grey", colour = NA) + 
  geom_raster(data = df_analysis %>% filter(resolution == "10km"), 
              aes(x = x, y = y, fill = mene), colour = NA) +
  coord_sf(crs = st_crs(study_ext_sf), datum = NA) + 
  scale_fill_viridis_c(name = "MENE visits\n(10km resolution)") + 
  theme(axis.text = element_blank(), axis.line = element_blank(), 
        axis.ticks = element_blank(), axis.title = element_blank(),
        panel.border = element_blank())

p2 <- ggplot() + 
  geom_sf(data = study_ext_sf, fill = "grey", colour = NA) + 
  geom_raster(data = df_analysis %>% filter(resolution == "10km"), 
              aes(x = x, y = y, fill = flickr), colour = NA) +
  coord_sf(crs = st_crs(study_ext_sf), datum = NA) + 
  scale_fill_viridis_c(name = "Flickr photos\n(10km resolution)") + 
  theme(axis.text = element_blank(), axis.line = element_blank(), 
        axis.ticks = element_blank(), axis.title = element_blank(),
        panel.border = element_blank())

p1 + p2 + plot_annotation(tag_levels = "a", tag_suffix = ")")
```

Hypothesis: The MENE visits and Flickr photos are proxies for different kinds of recreation. MENE visits are day-to-day local recreation; Flickr photos represent destination recreation. 

Test: MENE visits will not explain a large proportion of the variation in Flickr photos, 

We are fitting a poisson glm for each resolution with flickr photos as response, and mene visits as covariate. We plot $D^2$, coefficient estimate and spatial plot of residuals. We do this for the dataset with and without the outliers.

```{r comp_proxy}
fit_comp_model <- function(dat) {
  glm(flickr ~ mene, data = dat, family = "poisson")
}

est_corr <- function(dat) {
  cor.test(dat$flickr, dat$mene, method = "spearman")$estimate
}

comp_df <- df %>% filter_at(vars(flickr, mene), any_vars(. != 0))

comp_mods <- comp_df %>% 
  group_by(resolution) %>% 
  nest() %>% 
  mutate(mod = map(data, fit_comp_model),
         mod_tidy = map(mod, tidy),
         mod_glance = map(mod, glance),
         mod_resid = map(mod, residuals, "pearson"),
         mod_cor = map_dbl(data, est_corr))

d2 <- comp_mods %>% 
  select(resolution, mod_glance) %>% 
  unnest() %>% 
  mutate(d2 = (null.deviance - deviance)/null.deviance)


coeff <- comp_mods %>% 
  select(resolution, mod_tidy) %>% 
  unnest() %>% 
  filter(term == "mene") %>% 
  select(resolution, estimate, std.error) 

p1 <- ggplot(d2, aes(x = resolution, y = d2, group = 1)) + 
  geom_point() + 
  stat_summary(fun.y = sum, geom = "line")

p2 <- ggplot(coeff, aes(x = resolution, y = estimate, group = 1)) + 
  geom_point() + 
  stat_summary(fun.y = sum, geom = "line") + 
  ylab("coefficient estimate")

p1 + p2

ggplot(comp_df, aes(x = flickr, y = mene)) + 
  geom_point() + 
  geom_smooth(method = "glm", method.args = list(family = "poisson")) + 
  geom_text(data = d2, 
            aes(label = paste0("R^2  == ", round(d2, 2))), 
            x = -Inf, 
            y = Inf, 
            hjust = -0.5, 
            vjust = 1.5, 
            parse = TRUE) + 
  facet_wrap(~resolution, scales = "free") + 
  labs(x = "Flickr photographs", y = "MENE visits")
```

Spatial distribution of the residuals

```{r comp_proxy_spatial, fig.height = 8, fig.width = 10}
mod_resids <- comp_mods %>% 
  select(resolution, data, mod_resid) %>% 
  unnest()

plots <- map(unique(df$resolution), function (rln) {
  p1 <- ggplot() + 
    geom_sf(data = study_ext_sf, fill = "lightgrey", colour = NA) +
    geom_raster(data = mod_resids %>% filter(resolution == rln), 
                aes(x = x, y = y, fill = mod_resid)) + 
    coord_sf(crs = st_crs(study_ext_sf), datum = NA) + 
    scale_fill_gradient2("Pearson residuals", low = "#984ea3", high = "#4daf4a") + 
    theme(axis.title = element_blank(), 
          axis.text = element_blank(),
          axis.ticks = element_blank(),
          panel.border = element_blank())
})

(plots[[1]] + plots[[2]]) / (plots[[3]] + plots[[4]]) + 
  plot_annotation(tag_levels = "a", tag_suffix = ")")
```

When the residuals are positive, the number of flickr photos is much higher than expected based on the MENE visits. The residuals are more often positive than negative, and by a bigger margin. This means that when they diverge from each other, it's because there are more flickr photos than expected. We could do a more detailed analysis, but looks like the higher positive residuals are mainly around National Parks. 

# Q2: What are the relative importances of drivers of supply of and demand for ecosystem services at different scales?

Hypothesis: supply will be a more important predictor of the flickr photos, demand of the MENE visits. 

Test: variance partitioning

## Model selection

We fit 3 negative binomial models for each resolution and response type. The models are supply, demand and full (combined supply and demand models):

- Proportion of agricultural land cover (lcm_agri; supply)
- Proporiton of natural land covers (lcm_prop; supply) - taken this out for now
- Diversity of land-cover types (lcm_shei; supply)
- Mean elevation (dem__mean_range; supply)
- Proportion of area covered by protected area (pa; supply)
- Total population (pop; demand)
- Distance to nearest urban area (dist; supply)

```{r supplydemand_mods}
df_analysis_n <- df_analysis %>% 
  gather(dataset, 
         response, 
         -resolution, 
         -x, -y, 
         -cov_supply, 
         -cov_demand)

fit_mod_full <- function(dat) {
  #con = gamlss.control(trace = FALSE)
  glm.nb(response ~ lcm_agri + lcm_forest + lcm_coast + lcm_shei + dem_range + pa + pop + dist,
         data = dat)
}

fit_mod_supply <- function(dat) {
  glm.nb(response ~ lcm_agri + lcm_forest + lcm_coast + lcm_shei + dem_range + pa,
         data = dat)
}

fit_mod_demand <- function(dat) {
  glm.nb(response ~ pop + dist,
         data = dat)
}

part_var <- function(dat) {
  resp <- dat %>% pull(response)
  pred <- dat %>% dplyr::select(cov_supply, cov_demand)
  part <- hier.part.nb(resp, pred, gof = "logLik")$I.perc
  out <- tibble(var = rownames(part), expl = part$I)
}

mod <- df_analysis_n %>% 
  group_by(resolution, dataset) %>% 
  nest() %>% 
  mutate(mod_full = map(data, fit_mod_full),
         mod_supply = map(data, fit_mod_supply),
         mod_demand = map(data, fit_mod_demand),
         mod_full_D2 = map_dbl(mod_full, 
                               function(x) (x$null.deviance - x$deviance) / x$null.deviance),
         mod_demand_D2 = map_dbl(mod_demand, 
                                 function(x) (x$null.deviance - x$deviance) / x$null.deviance),
         mod_supply_D2 = map_dbl(mod_supply, 
                                 function(x) (x$null.deviance - x$deviance) / x$null.deviance),
         mod_tidy = map(mod_full, tidy),
         mod_part = map(data, part_var),
         mod_resid = map(mod_full, resid))

mod_part <- mod %>% 
  dplyr::select(resolution, dataset, mod_part) %>% 
  unnest() %>% 
  mutate(cov = factor(var, 
                      levels = c(cov_demand, cov_supply), 
                      labels = c(cov_demand_lab, cov_supply_lab)),
         cov_type = case_when(var %in% cov_supply ~ "Supply", 
                              TRUE ~ "Demand"),
         dataset = factor(dataset, labels = c("Flickr photos", "MENE visits")))

mod_stats <- mod %>%
  dplyr::select(resolution, dataset, mod_tidy) %>% 
  unnest() %>% 
  filter(term != "(Intercept)") %>% 
  mutate(lci = estimate - 1.96*std.error,
         uci = estimate + 1.96*std.error) %>% 
  select(resolution, dataset, var = term, coef = estimate, lci, uci) %>% 
  mutate(cov = factor(var, 
                      levels = c(cov_demand, cov_supply), 
                      labels = c(cov_demand_lab, cov_supply_lab)),
         cov_type = case_when(var %in% cov_supply ~ "Supply", 
                              TRUE ~ "Demand"),
         dataset = factor(dataset, labels = c("Flickr photos", "MENE visits")))

mod_aic <- mod %>%
  mutate(mod_full_aic = map_dbl(mod_full, function(x) x$aic),
         mod_demand_aic = map_dbl(mod_demand, function(x) x$aic),
         mod_supply_aic = map_dbl(mod_supply, function(x) x$aic)) %>% 
  select(resolution, dataset, mod_full_aic, mod_demand_aic, mod_supply_aic)
mod_aic %>% kable
write_csv(mod_aic, "doc/table1_mod_aic.csv")
```

In all cases the full (supply & demand) model is the best performing model as judged by AIC. At all resolutions, there is more support for the demand than supply model when MENE observations are used as a proxy for recreation. Similarly, at all resolutions there is more support for the supply than demand model when flickr photos are used as a proxy. 

### Variance partitioning

Following the plot from [Keil and Chase, 2019](https://www.nature.com/articles/s41559-019-0799-0.epdf?shared_access_token=t0H3KjubyHGCpiRw6rsWmdRgN0jAjWel9jnR3ZoTv0Oibl38INTmLHc9kqB6xeu5KEJ3UYeJOAeAWz3H5zlkKUTa_QNy9R-EbxoZlbisdLEzk_Y3BGp3AJV0jomrNL-fQycUYw6PLbOrON6gVoIOmfFUOVgCsPcgZphsqvzRUwM%3D): 

```{r, fig.height = 2, fig.width = 10}
mod_D2 <- mod %>%
  dplyr::select(resolution, dataset, mod_full_D2, mod_demand_D2, mod_supply_D2) %>% 
  mutate(dataset = factor(dataset, labels = c("Flickr photos", "MENE visits")),
         demand_ind = mod_full_D2 - mod_supply_D2,
         supply_ind = mod_full_D2 - mod_demand_D2,
         overlap = mod_full_D2 - (demand_ind + supply_ind),
         remain = 1 - mod_full_D2)

var_part_plot <- mod_D2 %>% 
  mutate(Demand_start = 0, 
         Demand_end = mod_demand_D2,
         Supply_start = demand_ind,
         Supply_end = mod_full_D2) %>% 
  select(resolution, dataset, Demand_start, Demand_end, Supply_start, Supply_end) %>% 
  gather(key, value, -resolution, -dataset) %>% 
  separate(key, into = c("Type", "pos")) %>% 
  spread(pos, value)

plot_test <- ggplot() + 
  geom_linerange(data = var_part_plot, 
       aes(ymin = start, ymax = end, x = Type, colour = Type),
       position = position_dodge(width = 0.6), 
       size = 5) + 
  coord_flip() + 
  ylim(c(0, 1)) + 
  facet_grid(resolution~dataset)

dat_sml <- filter(var_part_plot, resolution == "10km", dataset == "Flickr photos")

plot_test <- ggplot() + 
  geom_linerange(data = dat_sml, 
       aes(ymin = start, ymax = end, x = Type, colour = Type),
       size = 25) + 
  geom_hline(data = mod_D2 %>% filter(resolution == "10km", dataset == "Flickr photos"), 
             aes(yintercept = mod_full_D2)) + 
  coord_flip() + 
  ylim(c(0, 1)) +
  theme(panel.border = element_blank(),
        legend.position = "none",
        axis.ticks = element_blank(),
        axis.text = element_blank(),
        axis.title = element_blank())
  
b1 <- bracketsGrob(0.33, 0, 0, 0, h=0.05, lwd=2, col="red")
plot_test +  annotation_custom(b1) + scale_y_continuous(expand=c(-3,0))
```

Total variance explained and how it's partitioned for the full model 

```{r varpart, fig.width = 8, fig.height = 6}
p1 <- ggplot(mod_R2, aes(x = resolution, y = mod_R2)) + 
  geom_bar(stat = "identity") + 
  facet_wrap(~dataset) + 
  labs(x = "", y = expression(R^{2})) + 
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        panel.spacing = unit(2, "lines"),
        strip.background = element_blank())

p2 <- ggplot(mod_part, aes(x = resolution, y = expl, fill = cov)) + 
  scale_fill_viridis_d(option = "B", name = "Covariate") + 
  geom_bar(stat = "identity", position = "stack") + 
  facet_wrap(~dataset) + 
  labs(x = "Resolution", y = "Variance explained %") + 
  theme(strip.background = element_blank(),
        panel.spacing = unit(2, "lines"),
        strip.text = element_blank())

p3 <- ggplot(mod_part, aes(x = resolution, y = expl, fill = cov_type)) + 
  scale_fill_manual(values = c("#984ea3", "#4daf4a"), name = "") + 
  geom_bar(stat = "identity", position = "stack") + 
  facet_wrap(~dataset) + 
  labs(x = "Resolution", y = "Variance explained %")

p1 + p2 + 
  plot_layout(ncol = 1, heights = c(1, 3)) + 
  plot_annotation(tag_levels = "a", tag_suffix = ")")
```

- When using Flickr as a proxy, the supply part of the model counts for > 50% of the explained variance at all resolutions.
- When using MENE visits as a proxy, the supply part of the model never accounts for more than `r round(max(mod_part %>% filter(cov_type == "Supply", dataset == "MENE visits") %>% group_by(resolution) %>% summarise(expl = sum(expl)) %>% pull(expl)))`% of the explained variance
- The full model explains slightly less variance in the flickr data than it does the MENE data
- Scale dependencies: in both cases, the coarser the scale, the more variance is explained by demand for rather than supply of the service (although this is very marginal in the flickr model). 

### Variable relationships

Try the method from Keil and Chase 2019 where cell area is included as an interaction with each term, then plot the effects. 

```{r}

```

```{r, fig.width = 10, fig.height = 10}
ggplot(mod_stats, aes(x = cov, y = coef, ymin = lci, ymax = uci, group = resolution, shape = resolution, colour = cov_type)) + 
  geom_pointrange(position = position_dodge(0.8)) + 
  #geom_errorbar(position = position_dodge(0.5), ) + 
  geom_hline(yintercept = 0, linetype = "dashed") + 
  scale_colour_manual(values = c("#984ea3", "#4daf4a"), name = "") + 
  xlab("") + ylab(expression("Coefficient Estimate " %+-% " 95% CI")) + 
  facet_wrap(~dataset, ncol = 1)
```

## Session Info

```{r session_info}
session <- devtools::session_info()
session[[1]]
session[[2]] %>% select(package, loadedversion, source) %>% kable
```